{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d85ecbb",
   "metadata": {},
   "source": [
    "# Task5_Model_Interpretability.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df73e97e",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b09bb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Objective: Use model interpretability tools (LIME & SHAP) to explain NER model predictions.\n",
    "\n",
    "# --- Mount Google Drive ---\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# --- Step 1: Install Necessary Libraries ---\n",
    "!pip install transformers datasets seqeval accelerate evaluate\n",
    "!pip install lime shap\n",
    "\n",
    "# IMPORTANT: After running this cell, if prompted, click \"Restart runtime\"\n",
    "# and then \"Run all cells\" to ensure all libraries are correctly loaded.\n",
    "\n",
    "# --- Step 2: Import Libraries ---\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693549f1",
   "metadata": {},
   "source": [
    "# --- Configuration for Model Loading ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83fc5a5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: Adjust 'colab_projects/EthioMart_NER' to your desired base path in Google Drive\n",
    "DRIVE_PROJECT_BASE_PATH = \"/content/drive/MyDrive/colab_projects/EthioMart_NER\"\n",
    "\n",
    "# Path to the best performing model saved in your Google Drive from Task 4\n",
    "# This path should ideally be read from a file generated by Task 4, or hardcoded if Task 4 already ran.\n",
    "# For direct execution, we hardcode it based on previous Task 4 output.\n",
    "BEST_MODEL_PATH = os.path.join(DRIVE_PROJECT_BASE_PATH, \"XLM-R-Amharic-NER_ner_output/final_model\")\n",
    "# Alternatively, read from file if it exists:\n",
    "# try:\n",
    "#     with open(os.path.join(DRIVE_PROJECT_BASE_PATH, \"best_model_path.txt\"), \"r\") as f:\n",
    "#         BEST_MODEL_PATH = f.read().strip()\n",
    "#     print(f\"Loaded best model path from file: {BEST_MODEL_PATH}\")\n",
    "# except FileNotFoundError:\n",
    "#     print(\"best_model_path.txt not found. Using default BEST_MODEL_PATH.\")\n",
    "\n",
    "\n",
    "# Define your entity types (must match what you used for training)\n",
    "LABEL_NAMES = [\"O\", \"B-PRODUCT\", \"I-PRODUCT\", \"B-LOC\", \"I-LOC\", \"B-PRICE\", \"I-PRICE\"]\n",
    "\n",
    "# --- Step 3: Load the Best Fine-Tuned Model and Tokenizer ---\n",
    "print(f\"Loading best model and tokenizer from: {BEST_MODEL_PATH}\")\n",
    "try:\n",
    "    model = AutoModelForTokenClassification.from_pretrained(BEST_MODEL_PATH)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(BEST_MODEL_PATH)\n",
    "    ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
    "    \n",
    "    id2label = model.config.id2label\n",
    "    label2id = {v: k for k, v in id2label.items()}\n",
    "    print(f\"Model's ID to Label mapping: {id2label}\")\n",
    "    print(f\"Model's Label to ID mapping: {label2id}\")\n",
    "    model_loaded = True\n",
    "except Exception as e:\n",
    "    print(f\"Error loading best model: {e}. Skipping interpretability tasks.\")\n",
    "    model_loaded = False\n",
    "\n",
    "\n",
    "if model_loaded:\n",
    "    # --- Step 4: Prepare Custom Prediction Functions for LIME/SHAP ---\n",
    "\n",
    "    def predict_proba_for_token_classification(texts: list[str], target_token_idx: int = 0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Custom prediction function for LIME.\n",
    "        It takes a list of texts, tokenizes them, gets model predictions,\n",
    "        and returns probabilities for the TARGET_TOKEN_IDX.\n",
    "        This is a simplification for LIME on a single token for demonstration.\n",
    "        \"\"\"\n",
    "        tokenized_inputs = tokenizer(\n",
    "            texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(**tokenized_inputs).logits\n",
    "\n",
    "        probabilities = torch.softmax(logits, dim=-1).cpu().detach().numpy()\n",
    "\n",
    "        output_probs = []\n",
    "        for i in range(len(texts)):\n",
    "            if 1 < probabilities.shape[1]:\n",
    "                output_probs.append(probabilities[i, 1, :])\n",
    "            else:\n",
    "                output_probs.append(np.zeros(len(LABEL_NAMES)))\n",
    "        return np.array(output_probs)\n",
    "\n",
    "    # --- Step 5: Implement LIME (Local Interpretable Model-agnostic Explanations) ---\n",
    "\n",
    "    print(\"\\n--- LIME Explanations ---\")\n",
    "    explainer_lime = LimeTextExplainer(class_names=LABEL_NAMES)\n",
    "\n",
    "    example_sentence_lime = \"አዲስ ስልክ iPhone 15 Pro Max ዋጋው 70000 ብር ሲሆን በአዲስ አበባ ይገኛል\"\n",
    "    pipe_result_lime = ner_pipeline(example_sentence_lime)\n",
    "    print(f\"Pipeline prediction for LIME example: {pipe_result_lime}\")\n",
    "\n",
    "    word_to_explain_lime = \"iPhone\"\n",
    "    if word_to_explain_lime in example_sentence_lime:\n",
    "        target_label_id_for_lime = label2id.get(\"B-PRODUCT\", 0)\n",
    "        explanation_lime = explainer_lime.explain_instance(\n",
    "            text_instance=example_sentence_lime,\n",
    "            classifier_fn=lambda texts: predict_proba_for_token_classification(texts, target_token_idx=1),\n",
    "            labels=[target_label_id_for_lime],\n",
    "            num_features=5,\n",
    "            num_samples=1000\n",
    "        )\n",
    "        print(f\"\\nLIME Explanation for '{word_to_explain_lime}' as '{id2label[target_label_id_for_lime]}' in: '{example_sentence_lime}'\")\n",
    "        for feature, weight in explanation_lime.as_list(label=target_label_id_for_lime):\n",
    "            print(f\"  - '{feature}': {weight:.4f}\")\n",
    "    else:\n",
    "        print(f\"'{word_to_explain_lime}' not found in the example sentence for LIME explanation.\")\n",
    "\n",
    "    # --- SHAP Explanations ---\n",
    "    print(\"\\n--- SHAP Explanations ---\")\n",
    "\n",
    "    def ner_shap_predict_fn(texts: list[str]) -> np.ndarray:\n",
    "        \"\"\"Prediction function for SHAP: returns flattened probabilities.\"\"\"\n",
    "        all_flat_probs = []\n",
    "        for text in texts:\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(model.device)\n",
    "            with torch.no_grad():\n",
    "                logits = model(**inputs).logits\n",
    "            probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
    "            flat_probs = probs.reshape(-1)\n",
    "            all_flat_probs.append(flat_probs)\n",
    "        max_flat_len = max(len(p) for p in all_flat_probs)\n",
    "        padded_flat_probs = []\n",
    "        for p in all_flat_probs:\n",
    "            padded_flat_probs.append(np.pad(p, (0, max_flat_len - len(p)), 'constant'))\n",
    "        return np.array(padded_flat_probs)\n",
    "\n",
    "    # Define a small background dataset for SHAP KernelExplainer\n",
    "    shap_background_text = \"ስልክ ዋጋ ብር አዲስ አበባ\"\n",
    "    background_data_for_shap = [shap_background_text]\n",
    "\n",
    "    # Initialize the SHAP Text masker with the tokenizer and background data.\n",
    "    masker_shap = shap.maskers.Text(tokenizer, background_data_for_shap)\n",
    "\n",
    "    # Create a SHAP explainer using the high-level API\n",
    "    explainer_shap = shap.Explainer(\n",
    "        model=ner_shap_predict_fn,\n",
    "        masker=masker_shap, # Pass the initialized masker object\n",
    "        link=\"identity\" # Use \"identity\" as predict_fn returns probabilities\n",
    "    )\n",
    "\n",
    "    example_sentence_shap = \"አዲስ ስልክ iPhone 15 Pro Max ዋጋው 70000 ብር ሲሆን በአዲስ አበባ ይገኛል\"\n",
    "\n",
    "    try:\n",
    "        shap_values = explainer_shap([example_sentence_shap])\n",
    "        \n",
    "        print(f\"\\nSHAP Explanation for: '{example_sentence_shap}'\")\n",
    "        print(\"For detailed visualization, run `shap.plots.text(shap_values)` in a Jupyter environment.\")\n",
    "        print(\"Alternatively, inspect `shap_values.data` (tokens) and `shap_values.values` (importance scores).\")\n",
    "        \n",
    "        if hasattr(shap_values, 'data') and hasattr(shap_values, 'values') and len(shap_values.values) > 0:\n",
    "            loc_entity_from_pipeline = None\n",
    "            for entity in ner_pipeline(example_sentence_shap):\n",
    "                if entity['entity_group'] == 'LOC':\n",
    "                    loc_entity_from_pipeline = entity\n",
    "                    break\n",
    "\n",
    "            if loc_entity_from_pipeline:\n",
    "                print(f\"\\nFocusing on: {loc_entity_from_pipeline['word']} (Predicted as {loc_entity_from_pipeline['entity_group']})\")\n",
    "                text_tokens = shap_values.data[0]\n",
    "                token_shap_values_for_labels = shap_values.values[0]\n",
    "                \n",
    "                print(\"Approximate Feature importances (word: SHAP value summed across all labels):\")\n",
    "                if len(text_tokens) == token_shap_values_for_labels.shape[0]:\n",
    "                    for i in range(len(text_tokens)):\n",
    "                        total_contrib = np.sum(np.abs(token_shap_values_for_labels[i, :]))\n",
    "                        print(f\"  '{text_tokens[i]}': {total_contrib:.4f}\")\n",
    "                else:\n",
    "                    print(\"Cannot precisely map SHAP values to text tokens for simple print. Use `shap.plots.text`.\")\n",
    "            else:\n",
    "                print(\"No LOC entity found in pipeline prediction for SHAP example. Cannot provide targeted SHAP explanation.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during SHAP explanation: {e}\")\n",
    "        print(\"SHAP for token classification is complex. Ensure prediction function output matches SHAP's expectations.\")\n",
    "        print(\"If error persists, consider simpler examples or using `shap.plots.text()` in Jupyter.\")\n",
    "else:\n",
    "    print(\"\\nSkipping interpretability tasks as the model could not be loaded.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
